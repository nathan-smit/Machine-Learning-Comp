{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"path_name = 'data'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"upper_path = 'data-testing'","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":4089,"status":"ok","timestamp":1563656893729,"user":{"displayName":"Nathan Smit","photoUrl":"","userId":"11815403260906599728"},"user_tz":-120},"id":"Q3UF0FCHpJtl","outputId":"4b35c821-1bb5-452f-b4d4-75c1eb4587de","trusted":true},"cell_type":"code","source":"import glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom keras.preprocessing.image import ImageDataGenerator\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"YdF26_3ASAnw","trusted":true},"cell_type":"code","source":"#Fetch 1 car image for display\ncar1 = cv2.imread('../input/'+upper_path+'/'+path_name+'/'+path_name+'/training/00-damage/0050.JPEG')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom PIL import Image\ndef myFunc(image):\n    hsv_image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n    return hsv_image","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"gqS8x9kd_16C","trusted":true},"cell_type":"code","source":"#Keras image generator will be used to create additional training images\n\nimage_gen = ImageDataGenerator(rotation_range=35, # rotate the image 30 degrees\n                               width_shift_range=0.05, # Shift the pic width by a max of 10%\n                               height_shift_range=0.05, # Shift the pic height by a max of 10%\n                               rescale=1/255, # Rescale the image by normalzing it.\n                               shear_range=0.05, # Shear means cutting away part of the image (max 20%)\n                               zoom_range=0.1, # Zoom in by 20% max\n                               horizontal_flip=True, # Allo horizontal flipping\n                               fill_mode='nearest'\n                          #    ,\n                          #     n = myFunc # Fill in missing pixels with the nearest filled value\n                              # featurewise_center=True\n                              )","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"1ZWoxPLIJVY7","trusted":true},"cell_type":"code","source":"\nimage_gen_validate = ImageDataGenerator(\n                               rescale=1/255\n    #,\n     #                          preprocessing_function = myFunc # Rescale the image by normalzing it.       \n                               #featurewise_center=True\n                              )","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"BppNhDYYlZQx","trusted":true},"cell_type":"code","source":"#image_gen.mean=np.array([103.939, 116.779, 123.68],dtype=np.float32).reshape(1,1,3)","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"b96aIRqz0qvs","trusted":true},"cell_type":"code","source":"#image_gen_validate.mean=np.array([103.939, 116.779, 123.68],dtype=np.float32).reshape(1,1,3)","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"colab_type":"code","executionInfo":{"elapsed":3943,"status":"ok","timestamp":1563656893780,"user":{"displayName":"Nathan Smit","photoUrl":"","userId":"11815403260906599728"},"user_tz":-120},"id":"8du53conSTxr","outputId":"1192e631-dc6f-4561-fe65-58c32571f816","trusted":true},"cell_type":"code","source":"#Show an image of one of the damaged cars\nplt.imshow(car1)","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"colab_type":"code","executionInfo":{"elapsed":5031,"status":"ok","timestamp":1563656894901,"user":{"displayName":"Nathan Smit","photoUrl":"","userId":"11815403260906599728"},"user_tz":-120},"id":"ASqr1K4xShkI","outputId":"ee57e784-318d-4afe-d4a3-6ceca5525159","trusted":true},"cell_type":"code","source":"#Example Transformation of car image.\nplt.imshow(image_gen.random_transform(car1))","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":50},"colab_type":"code","executionInfo":{"elapsed":5000,"status":"ok","timestamp":1563656894905,"user":{"displayName":"Nathan Smit","photoUrl":"","userId":"11815403260906599728"},"user_tz":-120},"id":"AYDzTcACS6uX","outputId":"8a2c8318-67ee-48a0-ff6f-84c8495ed481","trusted":true},"cell_type":"code","source":"image_gen.flow_from_directory('../input/'+upper_path+'/'+path_name+'/'+path_name+'/training')","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":50},"colab_type":"code","executionInfo":{"elapsed":4981,"status":"ok","timestamp":1563656894908,"user":{"displayName":"Nathan Smit","photoUrl":"","userId":"11815403260906599728"},"user_tz":-120},"id":"t0TYnWtZTDvl","outputId":"42597db5-0833-4ecb-eeaf-cb9a6614d638","trusted":true},"cell_type":"code","source":"image_gen.flow_from_directory('../input/'+upper_path+'/'+path_name+'/'+path_name+'/validation')","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"LrHAXpYmTMEt","trusted":true},"cell_type":"code","source":"#Resizing images to 224x224.  I'm thinking of using VGG-16 for transfer learning so trying out this.  Average image size is 312 x 447\n# width,height,channels\nimage_shape = (299,299,3)\nbatch_size = 10\n#batch_size = 5","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"6nTZXdjCdzjW","trusted":true},"cell_type":"code","source":"from keras import optimizers\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"9zHIsIulkcVV","trusted":true},"cell_type":"code","source":"import numpy as np \nfrom keras.models import Model \nfrom keras.applications import Xception \nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.layers import Dense, GlobalAveragePooling2D \n#from keras.optimizers import Adam\nfrom keras.applications import imagenet_utils \nfrom keras.utils import np_utils \nfrom keras.callbacks import EarlyStopping ","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"colab_type":"code","executionInfo":{"elapsed":10623,"status":"ok","timestamp":1563656900618,"user":{"displayName":"Nathan Smit","photoUrl":"","userId":"11815403260906599728"},"user_tz":-120},"id":"ezmB1p1smlUi","outputId":"87c0c85a-72cb-4952-b137-b6d94f40b443","trusted":true},"cell_type":"code","source":"inception_model = InceptionV3(weights='imagenet', include_top=False) ","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"nR9pM6ymmuNA","trusted":true},"cell_type":"code","source":"from keras.layers import BatchNormalization\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers import Dropout\n\nx = inception_model.output \nx = GlobalAveragePooling2D()(x)\n#x = GlobalMaxPooling2D()(x)\nx = Dense(768, activation='relu')(x) \nx = BatchNormalization()(x)\nout = Dense(1, activation='sigmoid')(x)","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"x8Jgl170m5ov","trusted":true},"cell_type":"code","source":"model = Model(inputs=inception_model.input, outputs=out)","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"seEyRrl-m_EB","trusted":true},"cell_type":"code","source":"for layer in inception_model.layers:\n   layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":10600,"status":"ok","timestamp":1563656900649,"user":{"displayName":"Nathan Smit","photoUrl":"","userId":"11815403260906599728"},"user_tz":-120},"id":"-13slA6MnBgT","outputId":"6cbb10fb-1501-4986-81b7-3167a85e3d97","trusted":true},"cell_type":"code","source":"for i, layer in enumerate(model.layers):\n  print(i, layer.name) ","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"giqHMAMbnKVG","trusted":true},"cell_type":"code","source":"for layer in model.layers[:156]:\n    layer.trainable = False\nfor layer in model.layers[156:]:\n    layer.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":10587,"status":"ok","timestamp":1563656900662,"user":{"displayName":"Nathan Smit","photoUrl":"","userId":"11815403260906599728"},"user_tz":-120},"id":"IZZKKnrdGz-9","outputId":"cde00ffe-eb68-4b4a-941e-63a9ae7cd1b8","trusted":true},"cell_type":"code","source":"len(model.layers)","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"colab_type":"code","executionInfo":{"elapsed":10574,"status":"ok","timestamp":1563656900665,"user":{"displayName":"Nathan Smit","photoUrl":"","userId":"11815403260906599728"},"user_tz":-120},"id":"064Ebnn21krz","outputId":"ec5f2f99-a7bd-4a7d-aa1b-3441efd8fc50","trusted":true},"cell_type":"code","source":"print(\"Trainable layers:\", model.trainable_weights)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"4aff-yWRTkUo"},"cell_type":"markdown","source":"# Create the CNN"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":10561,"status":"ok","timestamp":1563656900668,"user":{"displayName":"Nathan Smit","photoUrl":"","userId":"11815403260906599728"},"user_tz":-120},"id":"FqEsrrfTTj3Q","outputId":"941c1a11-8714-47f8-cf15-9084e4157802","trusted":true},"cell_type":"code","source":"from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n\nmodel.compile(loss='binary_crossentropy',\n              #optimizer=optimizers.RMSprop(lr=0.0001),\n              #optimizer=optimizers.SGD(lr=0.0001, momentum=0.9),\n              #optimizer='Adagrad',\n              optimizer=optimizers.adam(lr=0.0001),\n              #optimizer=optimizers.nadam(lr=0.0001),\n              metrics=['accuracy'])\n\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_size = image_gen.flow_from_directory('../input/'+upper_path+'/'+path_name+'/'+path_name+'/validation').n\ntraining_size = image_gen.flow_from_directory('../input/'+upper_path+'/'+path_name+'/'+path_name+'/training').n","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":12542,"status":"ok","timestamp":1563563116867,"user":{"displayName":"Nathan Smit","photoUrl":"","userId":"11815403260906599728"},"user_tz":-120},"id":"ceWDyW1brsbZ","outputId":"49cfaa38-bfb0-464d-c41b-14760c85599e","trusted":true},"cell_type":"code","source":"#Train the model!\ntrain_image_gen = image_gen.flow_from_directory('../input/'+upper_path+'/'+path_name+'/'+path_name+'/training',\n                                               target_size=image_shape[:2],\n                                               batch_size=batch_size,\n                                               class_mode='binary')\n\ntrain_image_gen.class_indices\n\ntest_image_gen = image_gen_validate.flow_from_directory('../input/'+upper_path+'/'+path_name+'/'+path_name+'/validation',\n                                               target_size=image_shape[:2],\n                                               batch_size=batch_size,\n                                               class_mode='binary')\n\ntrain_image_gen.class_indices\n\nepochs = 150\n\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\n\nes = EarlyStopping(monitor='acc', mode='min', verbose=1, patience=6)\n\n#adding a LR reduction callback.  This will reduce the learning rate if the validation loss is not improving after 5 epochs\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.00008)\nfrom keras.callbacks import ModelCheckpoint\nmc =  ModelCheckpoint('Inception.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nfrom keras.callbacks import EarlyStopping\nes = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=10)\n\n#Run the model!\nresults = model.fit_generator(train_image_gen,epochs=epochs,\n                              steps_per_epoch=training_size/batch_size,\n                              validation_data=test_image_gen,\n                             validation_steps=validation_size/batch_size,\n                             callbacks=[mc])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"Inception.h5\"> Download File </a>"},{"metadata":{"colab":{},"colab_type":"code","id":"_UpeD5bmebKb","trusted":true},"cell_type":"code","source":"import pandas as pd\nmy_final_results = pd.DataFrame(results.history['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\ndir = './'\ncontent = os.listdir(dir)\nprint(content)","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"gQGnZO1vek-z","trusted":true},"cell_type":"code","source":"my_final_results.to_csv('results.csv')","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"-SWDuBP4V7II","trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\nt = f.suptitle('Transfer Learning Performance', fontsize=12)\nf.subplots_adjust(top=0.85, wspace=0.3)\n\nepoch_list = list(range(1,epochs+1))\nax1.plot(epoch_list, results.history['acc'], label='Train Accuracy')\nax1.set_ylim(ymin=0)\nax1.plot(epoch_list, results.history['val_acc'], label='Validation Accuracy')\nax1.set_xticks(np.arange(0, epochs+1, 5))\nax1.set_ylabel('Accuracy Value')\nax1.set_xlabel('Epoch')\nax1.set_title('Accuracy')\nl1 = ax1.legend(loc=\"best\")\n\nax2.plot(epoch_list, results.history['loss'], label='Train Loss')\nax2.plot(epoch_list, results.history['val_loss'], label='Validation Loss')\nax2.set_ylim(ymin=0)\nax2.set_xticks(np.arange(0, epochs+1, 5))\nax2.set_ylabel('Loss Value')\nax2.set_xlabel('Epoch')\nax2.set_title('Loss')\nl2 = ax2.legend(loc=\"best\")","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"ktcRkTmFrEKA","trusted":true},"cell_type":"code","source":"# save model\nmodel.save('final_model_x.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"LnGbtQ_kIH-E","trusted":true},"cell_type":"code","source":"# load the saved model\nfrom keras.models import load_model\n\nmodel = load_model('best_model_transfer_x.h5')","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Xception Car Problem Transfer Learn.ipynb","provenance":[],"toc_visible":true,"version":"0.3.2"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}